# Test AI Moderation System

## Quick Test Guide

### 1. Start the Application
```bash
# Terminal 1 - Backend
cd backend
npm run dev

# Terminal 2 - Frontend
cd frontend
npm run dev
```

### 2. Test Manual Reporting

**Steps:**
1. Open two browser windows (Window A and Window B)
2. Login with different accounts in each window
3. Both go to Stranger Chat page
4. Wait for them to match
5. In Window A, click the "Report" button (red button with warning icon)
6. Select a reason (e.g., "Nudity or Sexual Content")
7. Submit the report

**Expected Result:**
- âœ… Screenshot captured shows Window B's video (the partner)
- âœ… Report submitted successfully
- âœ… Admin panel shows:
  - Reporter: User A (with green ring)
  - Violator: User B (with red ring)
  - Screenshot: User B's video

### 3. Test AI Auto-Detection

**Steps:**
1. Open two browser windows
2. Start stranger chat in both
3. In Window B, show test content that might trigger AI:
   - Use test images/videos
   - Or use browser dev tools to simulate

**Expected AI Behavior:**

**50-69% Confidence (Silent Report):**
- âœ… No notification to users
- âœ… Report sent to admin panel for review
- âœ… Users can continue chatting

**70-84% Confidence (Warning):**
- âœ… Warning toast appears in Window A
- âœ… Violation counter increases (1/3, 2/3, 3/3)
- âœ… After 3 violations, auto-disconnect

**85%+ Confidence (Auto-Report):**
- âœ… Error toast: "Inappropriate content detected"
- âœ… Auto-disconnect immediately
- âœ… Report sent to admin panel
- âœ… Screenshot of Window B's video captured

### 4. Check Admin Panel

**Access Admin Panel:**
1. Login as admin user
2. Go to Admin Dashboard
3. Click "AI Moderation" tab

**Verify Display:**
- âœ… Reporter column shows correct user (green ring, "âœ“ Reporter" label)
- âœ… Violator column shows correct user (red ring, "âš  Violator" label)
- âœ… Violation Evidence shows screenshot (blurred, hover to view)
- âœ… AI Category shows detected type (Porn, Hentai, Sexy)
- âœ… Confidence shows percentage with progress bar
- âœ… Status shows pending/reviewed/action_taken/dismissed

### 5. Test Actions

**Admin Actions:**
1. Click "Review" to mark as reviewed
2. Click "Action" to mark action taken
3. Click "Dismiss" to dismiss the report
4. Click "View Full Evidence" to see full screenshot

**Expected:**
- âœ… Status updates immediately
- âœ… Report moves to appropriate category
- âœ… Stats update in real-time

## Console Logs to Watch

### Frontend Console (Window A - Reporter):
```
ðŸ” AI Check #1 - Status: connected
ðŸ“Š AI Predictions: Neutral: 95.0%, Porn: 3.0%, Sexy: 2.0%
âœ… Content check passed - safe

ðŸ” AI Check #2 - Status: connected
ðŸ“Š AI Predictions: Porn: 87.0%, Sexy: 10.0%, Neutral: 3.0%
âš ï¸ AI Moderation Alert: { violations: 1, confidence: '87.0%', category: 'Porn' }
ðŸš¨ AUTO-REPORTING due to high confidence
ðŸ“¤ Submitting report: { reporterId: 'xxx', reportedUserId: 'yyy', reason: 'Nudity or Sexual Content' }
```

### Backend Console:
```
ðŸ“¥ Received report: { reporterId: 'xxx', reportedUserId: 'yyy', reason: 'Nudity or Sexual Content', isAIDetected: true }
ðŸ“¤ Uploading screenshot to Cloudinary...
âœ… Screenshot uploaded: https://res.cloudinary.com/...
âœ… Report saved: Reporter xxx reported Violator yyy (AI Detected)
```

### Admin Panel Console:
```
ðŸ“Š Loading AI reports...
âœ… AI reports loaded: 5 reports
ðŸ“Š Stats: { total: 5, pending: 3, reviewed: 1, actionTaken: 1, dismissed: 0, avgConfidence: 0.78 }
```

## Troubleshooting

### Issue: AI not detecting
**Solution:** 
- Check browser console for TensorFlow.js errors
- Ensure camera permissions granted
- Wait 3 seconds for AI model to load
- Check "AI Protected" badge is green

### Issue: Screenshot is blank
**Solution:**
- Ensure partner's video is playing
- Check `remoteVideoRef.current.readyState >= 2`
- Verify video dimensions > 0

### Issue: Reporter/Violator wrong
**Solution:**
- Check `partnerUserId` is set correctly
- Verify socket.emit includes both IDs
- Check backend logs for correct IDs

### Issue: Admin panel not showing reports
**Solution:**
- Refresh admin panel
- Check backend logs for save errors
- Verify Cloudinary upload successful
- Check database for reports

## Success Criteria

âœ… AI detects inappropriate content in partner's video
âœ… Screenshot captures partner's video (not own video)
âœ… Reporter is the person who saw the violation
âœ… Violator is the person showing inappropriate content
âœ… Admin panel displays all information correctly
âœ… Confidence levels trigger appropriate actions
âœ… Manual reports work correctly
âœ… Silent reports (50-69%) don't notify users

## Notes

- AI model takes ~3 seconds to load on first use
- Checks run every 5 seconds during active chat
- Screenshots are high quality (0.9 JPEG quality)
- Cloudinary stores all evidence securely
- Reports are never deleted, only marked as dismissed
